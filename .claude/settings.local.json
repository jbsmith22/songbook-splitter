{
  "permissions": {
    "allow": [
      "Bash(git pull:*)",
      "Bash(dir:*)",
      "Bash(py -c:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git push)",
      "Bash(aws sts get-caller-identity:*)",
      "Bash(aws s3:*)",
      "Bash(aws dynamodb list-tables:*)",
      "Bash(aws lambda list-functions:*)",
      "Bash(aws ecs list-clusters:*)",
      "Bash(aws stepfunctions list-state-machines:*)",
      "Bash(aws ecs list-task-definitions:*)",
      "Bash(aws dynamodb describe-table:*)",
      "Bash(aws stepfunctions describe-state-machine:*)",
      "Bash(aws ecs describe-clusters:*)",
      "Bash(aws stepfunctions:*)",
      "Bash(aws dynamodb scan:*)",
      "Bash(aws logs describe-log-groups:*)",
      "Bash(aws dynamodb get-item:*)",
      "Bash(aws s3api put-bucket-cors:*)",
      "Bash(aws s3api get-bucket-cors:*)",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" -c \"import json; root=json.load\\(open\\(''reconciliation_decisions_2026-02-01.json''\\)\\); data=root[''decisions'']; completed=[k for k,v in data.items\\(\\) if v.get\\(''completed''\\)]; print\\(f''Total folders: {len\\(data\\)}''\\); print\\(f''Completed folders: {len\\(completed\\)}''\\); print\\(f''With file decisions: {sum\\(1 for k,v in data.items\\(\\) if v.get\\(\"\"completed\"\"\\) and v.get\\(\"\"fileDecisions\"\"\\)\\)}''\\); print\\(f''Total file operations: {sum\\(len\\(v.get\\(\"\"fileDecisions\"\", {}\\)\\) for k,v in data.items\\(\\) if v.get\\(\"\"completed\"\"\\)\\)}''\\)\")",
      "Bash(aws sso login:*)",
      "Bash(py:*)",
      "Bash(py scripts/analysis/analyze_match_quality_with_files.py:*)",
      "Bash(copy \"d:\\\\Work\\\\songbook-splitter\\\\app\\\\services\\\\improved_page_mapper.py\" \"d:\\\\Work\\\\songbook-splitter\\\\build\\\\lambda-package\\\\app\\\\services\"\")",
      "Bash(aws ecr get-login-password:*)",
      "Bash(docker login:*)",
      "Bash(docker build:*)",
      "Bash(docker tag:*)",
      "Bash(docker push:*)",
      "Bash(docker info:*)",
      "Bash(powershell -Command \"Invoke-RestMethod -Uri ''http://localhost:5000/api/page_analysis/america-songbook-complete''\")",
      "Bash(python:*)",
      "Bash(curl:*)",
      "Bash(aws dynamodb update-item:*)",
      "Bash(for book_id in v2-1e46e821cacf170d-2 v2-f9b37d9aca156dd9-2 v2-572ab40c580d53b6-2)",
      "Bash(do echo \"=== $book_id ===\")",
      "Bash(done)",
      "Bash(aws s3api list-objects-v2:*)",
      "Bash(aws configure list-profiles:*)",
      "Bash(timeout /t 3 /nobreak)",
      "Bash(timeout:*)",
      "Bash(\"/c/Program Files/Python312/python.exe\":*)",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c:*)",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport json\nfrom pathlib import Path\n\nFINAL_DIR = Path\\(''ProcessedSongs_Final''\\)\n\n# Check the double-prefixed folders that have manifests\ndouble_prefix_folders = [\n    ''Elton John/Elton John - Elton John - Greatest Hits 1970-2002'',\n    ''Queen/Queen - Queen - Greatest Hits'',\n    ''Billy Joel/Billy Joel - Billy Joel - 52nd Street'',\n    ''Beatles/Beatles - Beatles - Abbey Road'',\n]\n\nprint\\(''CHECKING DOUBLE-PREFIXED FOLDERS:''\\)\nprint\\(''='' * 70\\)\n\nfor folder_path in double_prefix_folders:\n    folder = FINAL_DIR / folder_path\n    manifest_path = folder / ''manifest.json''\n    \n    print\\(f''\\\\n{folder_path}''\\)\n    if manifest_path.exists\\(\\):\n        with open\\(manifest_path, encoding=''utf-8''\\) as f:\n            m = json.load\\(f\\)\n        print\\(f''  book_id: {m.get\\(\"\"book_id\"\"\\)}''\\)\n        print\\(f''  total_songs: {m.get\\(\"\"total_songs\"\", len\\(m.get\\(\"\"songs\"\", []\\)\\)\\)}''\\)\n        print\\(f''  PDFs: {len\\(list\\(folder.glob\\(\"\"*.pdf\"\"\\)\\)\\)}''\\)\n    else:\n        print\\(f''  NO MANIFEST''\\)\n\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" \"C:\\\\Users\\\\jbsmi\\\\AppData\\\\Local\\\\Temp\\\\claude\\\\d--Work-songbook-splitter\\\\959666dc-a6c8-4594-bde0-fba0b4ce945d\\\\scratchpad\\\\fix_broken_manifests.py\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" \"C:\\\\Users\\\\jbsmi\\\\AppData\\\\Local\\\\Temp\\\\claude\\\\d--Work-songbook-splitter\\\\959666dc-a6c8-4594-bde0-fba0b4ce945d\\\\scratchpad\\\\sync_provenance_with_manifests.py\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport boto3\nimport json\n\ns3 = boto3.client\\(''s3''\\)\nbucket = ''jsmith-output''\nbook_id = ''v2-2d6f17e729bd84e0-2''\n\n# Get page_analysis.json\nresp = s3.get_object\\(Bucket=bucket, Key=f''artifacts/{book_id}/page_analysis.json''\\)\npage_analysis = json.loads\\(resp[''Body''].read\\(\\).decode\\(''utf-8''\\)\\)\n\n# Check pages 12-15\npages = page_analysis.get\\(''pages'', []\\)\nprint\\(''CHECKING PAGES 12-15 for BOOGIE CHILD''\\)\nprint\\(''='' * 70\\)\n\nfor page in pages:\n    pdf_page = page.get\\(''pdf_page'', 0\\)\n    if 12 <= pdf_page <= 15:\n        print\\(f''\\\\nPDF Page {pdf_page}:''\\)\n        print\\(f''  content_type: {page.get\\(\"\"content_type\"\"\\)}''\\)\n        print\\(f''  detected_title: {page.get\\(\"\"detected_title\"\"\\)}''\\)\n        raw = page.get\\(''raw_response'', ''{}''\\)\n        try:\n            raw_data = json.loads\\(raw\\)\n            print\\(f''  raw content_type: {raw_data.get\\(\"\"content_type\"\"\\)}''\\)\n            print\\(f''  raw song_title: {raw_data.get\\(\"\"song_title\"\"\\)}''\\)\n        except:\n            print\\(f''  raw_response: {raw[:200]}''\\)\n\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport boto3\nimport json\n\ns3 = boto3.client\\(''s3''\\)\nbucket = ''jsmith-output''\nbook_id = ''v2-2d6f17e729bd84e0-2''\n\n# Get toc_discovery for text\nresp = s3.get_object\\(Bucket=bucket, Key=f''artifacts/{book_id}/toc_discovery.json''\\)\ntoc_disc = json.loads\\(resp[''Body''].read\\(\\).decode\\(''utf-8''\\)\\)\nextracted = toc_disc.get\\(''extracted_text'', {}\\)\n\nprint\\(''ALL POTENTIAL SONG STARTS \\(searching all pages\\)''\\)\nprint\\(''='' * 70\\)\n\n# Known song title patterns in this book\nfor page_num in range\\(1, 134\\):\n    page_key = str\\(page_num - 1\\)  # 0-indexed\n    if page_key in extracted:\n        text = extracted[page_key]\n        lines = text.strip\\(\\).split\\(''\\\\n''\\)[:5]\n        for line in lines:\n            line = line.strip\\(\\)\n            # Song title: all caps, reasonable length, at start of page\n            if \\(line.isupper\\(\\) and \n                3 < len\\(line\\) < 50 and \n                not line.startswith\\(''VERSE''\\) and\n                not line.startswith\\(''CODA''\\) and\n                not line.startswith\\(''CHORUS''\\) and\n                ''Copyright'' not in line\\):\n                print\\(f''Page {page_num-1}: {line}''\\)\n                break\n\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" \"C:/Users/jbsmi/AppData/Local/Temp/claude/d--Work-songbook-splitter/959666dc-a6c8-4594-bde0-fba0b4ce945d/scratchpad/analyze_all_books_page_analysis.py\")",
      "Bash(for f in *.pdf)",
      "Bash(do stat --printf=\"%s\\\\t%n\\\\n\" \"$f\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" \"C:/Users/jbsmi/AppData/Local/Temp/claude/d--Work-songbook-splitter/959666dc-a6c8-4594-bde0-fba0b4ce945d/scratchpad/check_pipeline_completion.py\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport subprocess\n# Check if there''s a v1 output folder different from ProcessedSongs_Final\nfrom pathlib import Path\n\ndirs_to_check = [\n    ''ProcessedSongs'',\n    ''ProcessedSongs_V1'', \n    ''ProcessedSongs_Archive'',\n    ''output'',\n    ''v1_output''\n]\n\nfor d in dirs_to_check:\n    p = Path\\(d\\)\n    if p.exists\\(\\):\n        count = len\\(list\\(p.glob\\(''**/*.pdf''\\)\\)\\)\n        print\\(f''{d}: exists, {count} PDFs''\\)\n    else:\n        print\\(f''{d}: does not exist''\\)\n\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport sys, json\ndata = json.load\\(sys.stdin\\)\nitem = data.get\\(''Item'', {}\\)\n\nprint\\(''Beatles - Abbey Road \\(v2-dc4c90d5e3d7da00-2\\):''\\)\nprint\\(f''  status: {item.get\\(\"\"status\"\", {}\\).get\\(\"\"S\"\"\\)}''\\)\nprint\\(f''  songs_extracted: {item.get\\(\"\"songs_extracted\"\", {}\\).get\\(\"\"N\"\", \"\"N/A\"\"\\)}''\\)\nprint\\(f''  processing_stage: {item.get\\(\"\"processing_stage\"\", {}\\).get\\(\"\"S\"\", \"\"N/A\"\"\\)}''\\)\n\")",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" scripts/analysis/generate_complete_lineage_data.py)",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" scripts/analysis/create_embedded_lineage_js.py)",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" -c \"import boto3; s3=boto3.client\\(''s3''\\); import json; resp=s3.get_object\\(Bucket=''jsmith-output'', Key=''artifacts/v2-00171fce4db3bdf9-2/output_files.json''\\); data=json.loads\\(resp[''Body''].read\\(\\)\\); print\\(json.dumps\\(data[''output_files''][0], indent=2\\)\\)\")",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" -c \"import json; data=json.load\\(open\\(''data/analysis/complete_lineage_data.json''\\)\\); print\\(''\\\\nS3 PDF Counts \\(first 10 books\\):''\\); [print\\(f''  {b[\"\"book_id\"\"]}: {b[\"\"artifacts\"\"][\"\"5_s3_output_pdfs\"\"][\"\"count\"\"]} PDFs''\\) for b in data[''books''][:10]]\")",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" scripts/check_unprocessed.py)",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" -c \"import boto3; dynamodb=boto3.resource\\(''dynamodb''\\); table=dynamodb.Table\\(''jsmith-processing-ledger''\\); resp=table.scan\\(FilterExpression=''begins_with\\(book_id, :v2\\)'', ExpressionAttributeValues={'':v2'': ''v2-''}, Limit=5\\); [print\\(f''{item[\"\"book_id\"\"]}: {item.get\\(\"\"source_pdf_uri\"\", \"\"N/A\"\"\\)}''\\) for item in resp[''Items'']]\")",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" scripts/batch_process_books.py 100)",
      "Bash(tee:*)",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" scripts/quick_status.py)",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" scripts/batch_process_books.py 300)",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" -c \"import json, boto3; sf=boto3.client\\(''stepfunctions''\\); b1=json.load\\(open\\(''data/batch_executions_1770448481.json''\\)\\); b2=json.load\\(open\\(''data/batch_executions_1770449379.json''\\)\\); from collections import Counter; c1=Counter\\(\\); c2=Counter\\(\\); [c1.update\\([sf.describe_execution\\(executionArn=e[''execution_arn'']\\)[''status'']]\\) for e in b1[''executions''][:10]]; [c2.update\\([sf.describe_execution\\(executionArn=e[''execution_arn'']\\)[''status'']]\\) for e in b2[''executions''][:10]]; print\\(f''BATCH 1 \\(100 books\\) - Sample of first 10:\\\\n  Running: {c1[\"\"RUNNING\"\"]}\\\\n  Succeeded: {c1[\"\"SUCCEEDED\"\"]}\\\\n  Failed: {c1[\"\"FAILED\"\"]}\\\\n''\\); print\\(f''BATCH 2 \\(300 books\\) - Sample of first 10:\\\\n  Running: {c2[\"\"RUNNING\"\"]}\\\\n  Succeeded: {c2[\"\"SUCCEEDED\"\"]}\\\\n  Failed: {c2[\"\"FAILED\"\"]}''\\)\")",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\":*)",
      "Bash(\"C:\\\\Program Files\\\\Python312\\\\python.exe\" -c:*)",
      "Bash(powershell:*)",
      "Bash(aws ecs describe-tasks:*)",
      "Bash(aws logs tail:*)",
      "Bash(aws logs get-log-events:*)",
      "Bash(aws logs:*)",
      "Bash(python3:*)",
      "Bash(ollama list:*)",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/prerender_source_songbooks.py --artist \"Cream\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/prerender_source_songbooks.py --artist \"Genesis\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/prerender_source_songbooks.py --artist \"Crowded House\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/prerender_source_songbooks.py --artist \"_Movie and TV\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/prerender_source_songbooks.py --test 1 --s3)",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/prerender_source_songbooks.py --test 5 --s3 --workers 4)",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/test_validation_broadway.py)",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/prerender_source_songbooks.py --all --s3 --workers 8)",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport json\ndata = json.load\\(open\\(''d:/Work/songbook-splitter/data/analysis/complete_lineage_data.json''\\)\\)\nbooks = data.get\\(''books'', []\\)\n\nprint\\(f''Total books in lineage data: {len\\(books\\)}''\\)\nprint\\(f''Total entries mentioned: {data.get\\(\"\"total_entries\"\", 0\\)}''\\)\n\n# Count by status\nstatuses = {}\nfor book in books:\n    status = book.get\\(''dynamodb'', {}\\).get\\(''status'', ''unknown''\\)\n    statuses[status] = statuses.get\\(status, 0\\) + 1\n\nprint\\(f''\\\\nBooks by status:''\\)\nfor status, count in sorted\\(statuses.items\\(\\)\\):\n    print\\(f''  {status}: {count}''\\)\n\n# Check for duplicates\nsources = {}\nfor book in books:\n    source = book.get\\(''dynamodb'', {}\\).get\\(''source_pdf_uri'', ''''\\)\n    if source:\n        if source not in sources:\n            sources[source] = []\n        sources[source].append\\(book[''book_id'']\\)\n\ndupes = {k: v for k, v in sources.items\\(\\) if len\\(v\\) > 1}\nprint\\(f''\\\\nUnique source PDFs: {len\\(sources\\)}''\\)\nprint\\(f''Duplicate source PDFs: {len\\(dupes\\)}''\\)\n\nif dupes:\n    print\\(f''\\\\nFirst 5 duplicates:''\\)\n    for i, \\(source, book_ids\\) in enumerate\\(list\\(dupes.items\\(\\)\\)[:5]\\):\n        print\\(f''  {source}''\\)\n        print\\(f''    Book IDs: {book_ids}''\\)\n\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/monitor_prerender_progress.py)",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/check_all_status.py)",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/comprehensive_vision_validation.py --test 5 --sample 3)",
      "Bash(\"/c/Program Files/Python312/python.exe\" scripts/comprehensive_vision_validation.py --test 10 --sample 3)",
      "Bash(find:*)",
      "Bash(for dir in /d/Work/songbook-splitter/ProcessedSongs_Final/*/*/)",
      "Bash(do if ls \"$dir\"/*.pdf)",
      "Bash(then echo \"$dir\")",
      "Bash(fi)",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport os\nfrom pathlib import Path\n\nbase = Path\\(''ProcessedSongs_Final''\\)\nbooks_with_pdfs = 0\ntotal_pdfs = 0\n\nfor artist_dir in base.iterdir\\(\\):\n    if not artist_dir.is_dir\\(\\):\n        continue\n    for book_dir in artist_dir.iterdir\\(\\):\n        if not book_dir.is_dir\\(\\):\n            continue\n        pdfs = list\\(book_dir.glob\\(''*.pdf''\\)\\)\n        if pdfs:\n            books_with_pdfs += 1\n            total_pdfs += len\\(pdfs\\)\n\nprint\\(f''Books with extracted songs: {books_with_pdfs}''\\)\nprint\\(f''Total extracted song PDFs: {total_pdfs}''\\)\n\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport os\nfrom pathlib import Path\n\nbase = Path\\(''ProcessedSongs_Final''\\)\nall_books = []\n\nfor artist_dir in base.iterdir\\(\\):\n    if not artist_dir.is_dir\\(\\):\n        continue\n    for book_dir in artist_dir.iterdir\\(\\):\n        if not book_dir.is_dir\\(\\):\n            continue\n        pdfs = list\\(book_dir.glob\\(''*.pdf''\\)\\)\n        if pdfs:\n            all_books.append\\(f''{artist_dir.name}/{book_dir.name}''\\)\n\nprint\\(f''Total book folders with PDFs: {len\\(all_books\\)}''\\)\nprint\\(f''\\\\nFirst 20 examples:''\\)\nfor book in sorted\\(all_books\\)[:20]:\n    print\\(f''  {book}''\\)\n\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport json\n\nresults = json.load\\(open\\(''prerender_results.json''\\)\\)\nprint\\(f\"\"Total books processed: {results[''total_books'']}\"\"\\)\nprint\\(f\"\"Successes: {results[''successes'']}\"\"\\)\nprint\\(f\"\"Failures: {results[''failures'']}\"\"\\)\nprint\\(f\"\"Total pages cached: {results[''total_pages_rendered''] + results[''total_pages_cached'']:,}\"\"\\)\nprint\\(f\"\"\\\\nFailed books:\"\"\\)\n\nfor book in results[''books'']:\n    if book[''pages_rendered''] == 0 and book[''pages_cached''] == 0:\n        print\\(f\"\"  - {book[''artist'']} - {book[''book_name'']}\"\"\\)\n        print\\(f\"\"    Status: {book[''status'']}\"\"\\)\n\")",
      "Bash(\"/c/Program Files/Python312/python.exe\" -c \"\nimport json\n\n# Find Beatles Abbey Road in lineage data\nwith open\\(''data/analysis/complete_lineage_data.json''\\) as f:\n    data = json.load\\(f\\)\n\n# Search for Abbey Road\nfor book in data[''books'']:\n    if ''Abbey Road'' in book.get\\(''dynamodb'', {}\\).get\\(''book_name'', ''''\\):\n        if ''Beatles'' in book.get\\(''dynamodb'', {}\\).get\\(''artist'', ''''\\):\n            print\\(json.dumps\\(book, indent=2\\)\\)\n            break\n\")"
    ]
  }
}
